---
title: "Alek's Portfolio"
---

# Bigfoot: Fact or Non-Fiction

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(leaflet)
library(dplyr)
library(shiny)
library(plotly)
```

```{r, echo=FALSE, warning=FALSE}
dat <- read.csv("C:/Users/ATrac/OneDrive/Documents/Web/atraczyk.github.io/bfro_reports_geocoded.csv")


# geo styling
g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showland = TRUE,
  landcolor = "grey",
  subunitcolor = "grey",
  countrycolor = "grey",
  countrywidth = 0.5,
  subunitwidth = 0.5
)

p <- plot_geo(dat, lat = ~latitude, lon = ~longitude) %>%
  add_markers(
    text = ~paste(title, classification, sep = "<br />"),
    color = ~classification, symbol = I("circle-dot"), size = I(3), hoverinfo = "text"
  ) %>%
  layout(
    title = 'Bigfoot Sightings United States', geo = g
  )

p
```

As populations continue to expand into previously rural areas, we find ourselves face to face with what lives in the deep of the woods. In this project, for the first time, we apply machine learning and super-duper advanced visualization techniques to finally answer the question: Bigfoot, fact or non-fiction.

## Species Study:
As most animals with a range the size of the United States tend to have more specific species within smaller areas (for instance, black, brown, or grizly bears), it's likely to be more beneficial to specify smaller Bigfoot ranges. Some theories already propose such subspieces of Bigfoot exist (Sasquatch in the Pacific Northwest,Grassman in Ohio, Skunk Ape in Florida). By finding these rangest, we should expect each species to act somewhat differently.

To extract this information from our data of Bigfoot sightings, we turn to unsupervised learning, and specifically Expectation Maximization (EM). We use expectation maximization over other clustering techniques (such as K-Mean's, or DBSCAN) for three reasons: 
  *EM clustering is refered to as "soft-margin" clustering. In EM this means each point of data is calculated as a probability of lying in each cluster. We can therefore tweak the model to remove outliers, and center in on Bigfoot ranges.
  *EM works much better than other techniques on data with different densities. As seen in the map at the top of the page, the density of Bigfoot sightings is quite different from one region to another.
  *Other clustering techniques tend to assume each cluster should have an equal number of data points within them. This can create clusters which are awkwardly shaped to make the clusters even
  
Now that we have a technique, we need to choose just how many classes are in our EM model (classes are the equivalent of species). To choose the optimum number of classes, we perform cross-validation on class sizes from 1 to 10. We choose to evaluate the performance of these models by Bayesian Information Criterion (BIC). We choose this metric over Akaike Information Criterion (AIC) as it has a larger penalty for larger models, and will help prevent us from overfitting the model. The code and results are below:

```{r, message=FALSE, warning=FALSE, include=TRUE,eval=FALSE}
library(EMCluster)
library(ggplot2)

##Read Data
dat <- read.csv("C:/Users/ATrac/OneDrive/Documents/Web/atraczyk.github.io/bfro_reports_geocoded.csv")
dat <- dat[!is.na(dat$latitude)&!is.na(dat$longitude),]

##Setup for loop
set.seed(0)
temp <-  seq(1:10)
cvresults <- data.frame(temp)

##for loop to run various sizes of cross validation
for (j in 1:2){
  for (i in 1:10){
    test <- simple.init(dat[,c("latitude","longitude")],nclass=i)
    test <- shortemcluster(dat[,c("latitude","longitude")],test)
    test2 <- emcluster(dat[,c("latitude","longitude")],test,assign.class = T)
    temp[i] <- summary(test2)$BIC
  }
  cvresults <- data.frame(cvresults,temp)
}

##Calculate mean,min,max of each class
cvresults <- cvresults[,-1]
cvresults[,"average"] <- rowMeans(cvresults,na.rm=T)
for (i in 1:nrow(cvresults)){
  cvresults[i,"min"] <- min(cvresults[i,],na.rm=T)
  cvresults[i,"max"] <- max(cvresults[i,],na.rm=T)
}
cvresults[,"classes"] <- 1:10
```
```{r, message=FALSE, warning=FALSE, include=FALSE}
library(EMCluster)
library(ggplot2)
cvresults <- read.csv("C:/Users/ATrac/OneDrive/Documents/cvresults.csv")
```
```{r}
##Plot cross validation results
ggplot(data=cvresults, aes(x=classes,y=average)) + geom_errorbar(aes(ymin=min,ymax=max),width=.1)+geom_line()+geom_point() + labs(x="Classes",y="BIC",title="Cross Validation Results")
```

From our cross validation, I chose 7 Classes. BIC was small, and larger classes started to see growing error bars (implying overfitting). We now calculate our EM model with 7 classes, and plot the results below:
```{r, message=FALSE, warning=FALSE, include=FALSE}
dat <- read.csv("C:/Users/ATrac/OneDrive/Documents/Web/atraczyk.github.io/bfro_reports_geocoded.csv")
dat <- dat[!is.na(dat$latitude)&!is.na(dat$longitude),]
```
```{r, message=FALSE, warning=FALSE}
set.seed(0)
test <- simple.init(dat[,c("latitude","longitude")],nclass=7)
test <- shortemcluster(dat[,c("latitude","longitude")],test)
test2 <- emcluster(dat[,c("latitude","longitude")],test,assign.class = T)

emclass <- dat[,c("latitude","longitude")]
emclass[,"Class"] <- as.factor(test2$class)
head(emclass)
```

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(plotly)

g <- list(
  scope = 'usa',
  projection = list(type = 'albers usa'),
  showland = TRUE,
  landcolor = "grey",
  subunitcolor = "grey",
  countrycolor = "grey",
  countrywidth = 0.5,
  subunitwidth = 0.5
)

p <- plot_geo(emclass, lat = ~latitude, lon = ~longitude) %>%
  add_markers(
    color = ~Class, symbol = I("circle-dot"), size = I(3)
  ) %>%
  layout(
    title = 'Bigfoot Sightings United States', geo = g
  )

p
```